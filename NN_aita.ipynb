{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tqdm import tqdm, notebook\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'aita_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ytr72</td>\n",
       "      <td>1.393275e+09</td>\n",
       "      <td>[AITA] Construction worker here</td>\n",
       "      <td>I have been on a parking structure project for...</td>\n",
       "      <td>False</td>\n",
       "      <td>too close to call</td>\n",
       "      <td>63</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>1.393279e+09</td>\n",
       "      <td>[AITA] I wrote an explanation in TIL and came ...</td>\n",
       "      <td>[Here is the post in question](http://www.redd...</td>\n",
       "      <td>False</td>\n",
       "      <td>asshole</td>\n",
       "      <td>52</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>1.393281e+09</td>\n",
       "      <td>[AITA] Threw my parent's donuts away</td>\n",
       "      <td>My parents are diabetic, morbidly obese, and a...</td>\n",
       "      <td>1393290576.0</td>\n",
       "      <td>asshole</td>\n",
       "      <td>140</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yu41e</td>\n",
       "      <td>1.393282e+09</td>\n",
       "      <td>[AITA] I Put My Empty Beer on a Bar Table</td>\n",
       "      <td>Relevant Facts:\\n\\n1) It was a crowded bar, th...</td>\n",
       "      <td>False</td>\n",
       "      <td>nothing happened</td>\n",
       "      <td>45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>1.393285e+09</td>\n",
       "      <td>I told a goth girl she looked like a clown.</td>\n",
       "      <td>I was four.</td>\n",
       "      <td>False</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167755</th>\n",
       "      <td>ex970f</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>AITA for telling my husband to f* off after he...</td>\n",
       "      <td>My husband (28M) and I (32F) are married for a...</td>\n",
       "      <td>1580584475.0</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>1373</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167756</th>\n",
       "      <td>ex97ye</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>AITA for refusing to give my ticket to my brot...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>False</td>\n",
       "      <td>no a-holes here</td>\n",
       "      <td>4</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167758</th>\n",
       "      <td>ex9dwo</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>AITA for attempting to keep my students out of...</td>\n",
       "      <td>Upfront apologies for formatting. I’m also try...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167759</th>\n",
       "      <td>ex9egs</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>WIBTA if I left my brothers fate up to the state?</td>\n",
       "      <td>A little back story my mom is a drug addict an...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>280</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167760</th>\n",
       "      <td>ex9g78</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>WIBTA for rocking the boat at work because my ...</td>\n",
       "      <td>I’m a (23F) apprentice in the trades. I work o...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>5</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129953 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     timestamp  \\\n",
       "0       1ytr72  1.393275e+09   \n",
       "1       1ytxov  1.393279e+09   \n",
       "2       1yu29c  1.393281e+09   \n",
       "3       1yu41e  1.393282e+09   \n",
       "4       1yu8hi  1.393285e+09   \n",
       "...        ...           ...   \n",
       "167755  ex970f  1.580577e+09   \n",
       "167756  ex97ye  1.580577e+09   \n",
       "167758  ex9dwo  1.580578e+09   \n",
       "167759  ex9egs  1.580578e+09   \n",
       "167760  ex9g78  1.580578e+09   \n",
       "\n",
       "                                                    title  \\\n",
       "0                         [AITA] Construction worker here   \n",
       "1       [AITA] I wrote an explanation in TIL and came ...   \n",
       "2                    [AITA] Threw my parent's donuts away   \n",
       "3               [AITA] I Put My Empty Beer on a Bar Table   \n",
       "4             I told a goth girl she looked like a clown.   \n",
       "...                                                   ...   \n",
       "167755  AITA for telling my husband to f* off after he...   \n",
       "167756  AITA for refusing to give my ticket to my brot...   \n",
       "167758  AITA for attempting to keep my students out of...   \n",
       "167759  WIBTA if I left my brothers fate up to the state?   \n",
       "167760  WIBTA for rocking the boat at work because my ...   \n",
       "\n",
       "                                                     body        edited  \\\n",
       "0       I have been on a parking structure project for...         False   \n",
       "1       [Here is the post in question](http://www.redd...         False   \n",
       "2       My parents are diabetic, morbidly obese, and a...  1393290576.0   \n",
       "3       Relevant Facts:\\n\\n1) It was a crowded bar, th...         False   \n",
       "4                                             I was four.         False   \n",
       "...                                                   ...           ...   \n",
       "167755  My husband (28M) and I (32F) are married for a...  1580584475.0   \n",
       "167756                                          [deleted]         False   \n",
       "167758  Upfront apologies for formatting. I’m also try...         False   \n",
       "167759  A little back story my mom is a drug addict an...         False   \n",
       "167760  I’m a (23F) apprentice in the trades. I work o...         False   \n",
       "\n",
       "                  verdict  score  num_comments  \n",
       "0       too close to call     63           9.0  \n",
       "1                 asshole     52          13.0  \n",
       "2                 asshole    140          27.0  \n",
       "3        nothing happened     45           7.0  \n",
       "4         not the asshole     74          15.0  \n",
       "...                   ...    ...           ...  \n",
       "167755     not the a-hole   1373         304.0  \n",
       "167756    no a-holes here      4          16.0  \n",
       "167758     not the a-hole      4          15.0  \n",
       "167759     not the a-hole    280         140.0  \n",
       "167760     not the a-hole      5          21.0  \n",
       "\n",
       "[129953 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(axis=0)\n",
    "df['verdict'] = df['verdict'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not the a-hole            75393\n",
      "asshole                   27449\n",
      "no a-holes here           15129\n",
      "everyone sucks             7417\n",
      "not enough info            2713\n",
      "                          ...  \n",
      "meta validation seeker        1\n",
      "shitpost (literally)          1\n",
      "slightly the asshole          1\n",
      "skirting asshole              1\n",
      "1/10th asshole                1\n",
      "Name: verdict, Length: 410, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df['verdict'].value_counts()\n",
    "print(counts)\n",
    "v = df['verdict']\n",
    "df = df[v.replace(counts.gt(300))]\n",
    "replace_dict = {\n",
    "    'not the asshole': 'not the a-hole',\n",
    "    'no a--holes here': 'no a-holes here'\n",
    "}\n",
    "df = df.replace({'verdict': replace_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole     75766\n",
       "asshole            27449\n",
       "no a-holes here    15432\n",
       "everyone sucks      7417\n",
       "not enough info     2713\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole    91198\n",
       "asshole           34866\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = df['verdict']\n",
    "df = df[v.replace(counts.gt(3000))]\n",
    "replace_dict = {\n",
    "    'no a-holes here': 'not the a-hole',\n",
    "    'everyone sucks': 'asshole'\n",
    "}\n",
    "df = df.replace({'verdict': replace_dict})\n",
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole    71536\n",
       "asshole           26863\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = df['body']\n",
    "df = df[v != '[deleted]']\n",
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asshole' 'not the a-hole']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "verdicts = df['verdict'].unique()\n",
    "print(verdicts)\n",
    "num_classes = len(verdicts)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    ignore_tokens = string.punctuation\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) \n",
    "                if not any(i in t for i in self.ignore_tokens) and len(t) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['edited'] = [0 if 'false' in d else 1 for d in df['edited'].str.lower() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_comments'] = np.log(df['num_comments'])\n",
    "df['score'] = np.log(df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['body'] = df['body'].str.lower() # convert to lowercase\n",
    "df['title'] = df['title'].str.lower() # convert to lowercase\n",
    "df['body'] = df[['title', 'body']].agg(' '.join, axis=1)\n",
    "\n",
    "df['body'] = df['body'].str.replace('[^\\w\\s]', ' ') # replace characters that are not alphanumeric or spaces\n",
    "# df['body'] = df['body'].str.replace('\\d+', '') # replace numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>1.393279e+09</td>\n",
       "      <td>[aita] i wrote an explanation in til and came ...</td>\n",
       "      <td>aita  i wrote an explanation in til and came ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>2.564949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>1.393281e+09</td>\n",
       "      <td>[aita] threw my parent's donuts away</td>\n",
       "      <td>aita  threw my parent s donuts away my parent...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.941642</td>\n",
       "      <td>3.295837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>1.393285e+09</td>\n",
       "      <td>i told a goth girl she looked like a clown.</td>\n",
       "      <td>i told a goth girl she looked like a clown  i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1yuc78</td>\n",
       "      <td>1.393287e+09</td>\n",
       "      <td>[aita]: argument i had with another redditor i...</td>\n",
       "      <td>aita   argument i had with another redditor i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1yugsc</td>\n",
       "      <td>1.393289e+09</td>\n",
       "      <td>aita had a disagreement about les miserables w...</td>\n",
       "      <td>aita had a disagreement about les miserables w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167754</th>\n",
       "      <td>ex94w5</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>aita for telling my sister she is being a spoi...</td>\n",
       "      <td>aita for telling my sister she is being a spoi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>3.135494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167755</th>\n",
       "      <td>ex970f</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>aita for telling my husband to f* off after he...</td>\n",
       "      <td>aita for telling my husband to f  off after he...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.224753</td>\n",
       "      <td>5.717028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167758</th>\n",
       "      <td>ex9dwo</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>aita for attempting to keep my students out of...</td>\n",
       "      <td>aita for attempting to keep my students out of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167759</th>\n",
       "      <td>ex9egs</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>wibta if i left my brothers fate up to the state?</td>\n",
       "      <td>wibta if i left my brothers fate up to the sta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.634790</td>\n",
       "      <td>4.941642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167760</th>\n",
       "      <td>ex9g78</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>wibta for rocking the boat at work because my ...</td>\n",
       "      <td>wibta for rocking the boat at work because my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.044522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98399 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     timestamp  \\\n",
       "1       1ytxov  1.393279e+09   \n",
       "2       1yu29c  1.393281e+09   \n",
       "4       1yu8hi  1.393285e+09   \n",
       "5       1yuc78  1.393287e+09   \n",
       "7       1yugsc  1.393289e+09   \n",
       "...        ...           ...   \n",
       "167754  ex94w5  1.580577e+09   \n",
       "167755  ex970f  1.580577e+09   \n",
       "167758  ex9dwo  1.580578e+09   \n",
       "167759  ex9egs  1.580578e+09   \n",
       "167760  ex9g78  1.580578e+09   \n",
       "\n",
       "                                                    title  \\\n",
       "1       [aita] i wrote an explanation in til and came ...   \n",
       "2                    [aita] threw my parent's donuts away   \n",
       "4             i told a goth girl she looked like a clown.   \n",
       "5       [aita]: argument i had with another redditor i...   \n",
       "7       aita had a disagreement about les miserables w...   \n",
       "...                                                   ...   \n",
       "167754  aita for telling my sister she is being a spoi...   \n",
       "167755  aita for telling my husband to f* off after he...   \n",
       "167758  aita for attempting to keep my students out of...   \n",
       "167759  wibta if i left my brothers fate up to the state?   \n",
       "167760  wibta for rocking the boat at work because my ...   \n",
       "\n",
       "                                                     body  edited  verdict  \\\n",
       "1        aita  i wrote an explanation in til and came ...       0        0   \n",
       "2        aita  threw my parent s donuts away my parent...       1        0   \n",
       "4       i told a goth girl she looked like a clown  i ...       0        1   \n",
       "5        aita   argument i had with another redditor i...       1        0   \n",
       "7       aita had a disagreement about les miserables w...       0        0   \n",
       "...                                                   ...     ...      ...   \n",
       "167754  aita for telling my sister she is being a spoi...       1        1   \n",
       "167755  aita for telling my husband to f  off after he...       1        1   \n",
       "167758  aita for attempting to keep my students out of...       0        1   \n",
       "167759  wibta if i left my brothers fate up to the sta...       0        1   \n",
       "167760  wibta for rocking the boat at work because my ...       0        1   \n",
       "\n",
       "           score  num_comments  \n",
       "1       3.951244      2.564949  \n",
       "2       4.941642      3.295837  \n",
       "4       4.304065      2.708050  \n",
       "5       3.091042      1.098612  \n",
       "7       3.091042      2.708050  \n",
       "...          ...           ...  \n",
       "167754  2.772589      3.135494  \n",
       "167755  7.224753      5.717028  \n",
       "167758  1.386294      2.708050  \n",
       "167759  5.634790      4.941642  \n",
       "167760  1.609438      3.044522  \n",
       "\n",
       "[98399 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df['verdict'].unique()\n",
    "verdict_map = dict(zip(classes, range(len(classes))))\n",
    "df['verdict'] = df['verdict'].replace(verdict_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_temp = train_test_split(df, test_size=0.2, stratify=df['verdict'])\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp['verdict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = df_train[['edited', 'score', 'num_comments']].to_numpy()\n",
    "labels = df_train['verdict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=LemmaTokenizer()\n",
    "word_list = ['aita']\n",
    "\n",
    "stop_words = set(ENGLISH_STOP_WORDS.union(word_list))\n",
    "tokenized_stop = tokenizer(' '.join(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78719, 1000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, sublinear_tf=True, max_df=0.95, \n",
    "                             min_df=5, ngram_range=(1, 2), tokenizer=tokenizer, stop_words=tokenized_stop)\n",
    "# vectorizer = TfidfVectorizer(max_features=1000, sublinear_tf=True, max_df=0.95, \n",
    "#                              min_df=5, ngram_range=(1, 2))\n",
    "text_features = vectorizer.fit_transform(df_train['body']).toarray()\n",
    "print(text_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names = ['edited', 'score', 'num_comments'] + feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2315.89 MiB, increment: -4.41 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78719, 1003)\n"
     ]
    }
   ],
   "source": [
    "text_features = np.array(np.hstack((transformed_data, text_features)))\n",
    "print(text_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2318.03 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n",
      "(78719, 1003)\n",
      "(78719,)\n"
     ]
    }
   ],
   "source": [
    "X_train = text_features\n",
    "y_train = np.array(labels)\n",
    "input_size = len(X_train[0])\n",
    "print(input_size)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=0)\n",
    "# X_under, y_under = rus.fit_resample(X_train, y_train)\n",
    "# print(X_under.shape)\n",
    "# print(y_under.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114458, 1003)\n",
      "(114458,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=0)\n",
    "X_over, y_over = sm.fit_resample(X_train, y_train)\n",
    "print(X_over.shape)\n",
    "print(y_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=500, score_func=<function chi2 at 0x7f513fc7c710>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_rank = SelectKBest(chi2, k=500)\n",
    "feature_rank.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chi_squared</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201.909118</td>\n",
       "      <td>num_comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856.227565</td>\n",
       "      <td>edited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>110.007706</td>\n",
       "      <td>mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>94.058137</td>\n",
       "      <td>edit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>90.858121</td>\n",
       "      <td>mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>85.397753</td>\n",
       "      <td>dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>63.249996</td>\n",
       "      <td>wanting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>57.401888</td>\n",
       "      <td>wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>55.599275</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>50.809822</td>\n",
       "      <td>parent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>41.986487</td>\n",
       "      <td>mum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>40.609635</td>\n",
       "      <td>sibling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>37.994555</td>\n",
       "      <td>refusing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>35.992580</td>\n",
       "      <td>aunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>35.594154</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>33.531343</td>\n",
       "      <td>visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>31.825006</td>\n",
       "      <td>grandmother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>31.736895</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>30.598355</td>\n",
       "      <td>manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>30.516646</td>\n",
       "      <td>girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>29.140425</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>28.989717</td>\n",
       "      <td>shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>28.956307</td>\n",
       "      <td>joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>26.223959</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.207258</td>\n",
       "      <td>abusive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     chi_squared          word\n",
       "2    1201.909118  num_comments\n",
       "0     856.227565        edited\n",
       "579   110.007706           mom\n",
       "268    94.058137          edit\n",
       "586    90.858121        mother\n",
       "197    85.397753           dad\n",
       "950    63.249996       wanting\n",
       "969    57.401888          wife\n",
       "303    55.599275        family\n",
       "633    50.809822        parent\n",
       "592    41.986487           mum\n",
       "789    40.609635       sibling\n",
       "714    37.994555      refusing\n",
       "59     35.992580          aunt\n",
       "308    35.594154        father\n",
       "936    33.531343         visit\n",
       "382    31.825006   grandmother\n",
       "571    31.736895           mil\n",
       "548    30.598355       manager\n",
       "365    30.516646          girl\n",
       "516    29.140425          live\n",
       "777    28.989717         shift\n",
       "465    28.956307          joke\n",
       "435    26.223959         house\n",
       "6      26.207258       abusive"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = []\n",
    "for i, (score, feature) in enumerate(zip(feature_rank.scores_, feature_names)):\n",
    "    feat.append((score, feature))\n",
    "    \n",
    "dfObj = pd.DataFrame(feat, columns = ['chi_squared', 'word']) \n",
    "dfObj.sort_values(by=['chi_squared'], ascending = False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 1003)\n",
      "(9840,)\n"
     ]
    }
   ],
   "source": [
    "transformed_val = df_val[['edited', 'score', 'num_comments']].to_numpy()\n",
    "labels_val = df_val['verdict']\n",
    "X_val = np.array(np.hstack((transformed_val, vectorizer.transform(df_val['body']).toarray())))\n",
    "y_val = np.array(labels_val)\n",
    "del transformed_val\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3273.07 MiB, increment: -0.22 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process = make_pipeline(PowerTransformer(method='yeo-johnson'))\n",
    "# ct = ColumnTransformer([(\"power\", process, [x for x in range(0, 6)])], remainder='passthrough')\n",
    "# X_train = ct.fit_transform(X_train)\n",
    "# X_test = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3273.07 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(Variable(torch.from_numpy(X_over.astype(np.float32))), \n",
    "                                   Variable(torch.from_numpy(y_over.astype(np.long))))\n",
    "test_dataset = Data.TensorDataset(Variable(torch.from_numpy(X_val.astype(np.float32))), \n",
    "                                  Variable(torch.from_numpy(y_val.astype(np.long))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainHelper():\n",
    "    '''\n",
    "    Helper class that makes it a bit easier and cleaner to define the training routine\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,model,train_set,test_set,opts):\n",
    "        self.model = model \n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.epochs = opts['epochs']\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=opts['lr'], weight_decay=opts['weight_decay']) # optimizer method for gradient descent\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()                      # loss function\n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                                        batch_size=opts['batch_size'],\n",
    "                                                        shuffle=True)\n",
    "        self.test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                                       batch_size=opts['batch_size'],\n",
    "                                                       shuffle=True)\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.train() #put model in training mode\n",
    "        self.train_accuracy = []\n",
    "        self.train_bacc = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.tr_loss = []\n",
    "            for i, (data,labels) in notebook.tqdm(enumerate(self.train_loader),\n",
    "                                                   total = len(self.train_loader)):\n",
    "                self.model.train()\n",
    "                data, labels = data.to(self.device),labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(data)  \n",
    "                loss = self.criterion(outputs, labels) \n",
    "                loss.backward()                        \n",
    "                self.optimizer.step()                  \n",
    "                self.tr_loss.append(loss.item())\n",
    "                y_pred_softmax = torch.log_softmax(outputs.data, dim = 1)\n",
    "                _, predicted = torch.max(y_pred_softmax, dim = 1)\n",
    "#                 self.train_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
    "                self.train_accuracy.append(accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "                self.train_bacc.append(balanced_accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "\n",
    "            \n",
    "            self.test(epoch) # run through the validation set\n",
    "        \n",
    "    def test(self,epoch):\n",
    "            \n",
    "            self.model.eval()    # puts model in eval mode - not necessary for this demo but good to know\n",
    "            self.test_loss = []\n",
    "            self.test_accuracy = []\n",
    "            self.test_bacc = []\n",
    "\n",
    "            \n",
    "            for i, (data, labels) in enumerate(self.test_loader):\n",
    "                \n",
    "                data, labels = data.to(self.device),labels.to(self.device)\n",
    "                \n",
    "                # pass data through network\n",
    "                # turn off gradient calculation to speed up calcs and reduce memory\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(data)\n",
    "                \n",
    "                # make our predictions and update our loss info\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                self.test_loss.append(loss.item())\n",
    "                y_pred_softmax = torch.log_softmax(outputs.data, dim = 1)\n",
    "                _, predicted = torch.max(y_pred_softmax, dim = 1)\n",
    "                self.test_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
    "#                 self.test_accuracy.append(accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "                self.test_bacc.append(balanced_accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "\n",
    "            \n",
    "            print('epoch: {}, train loss: {}, test loss: {}, train acc: {}, train balacc: {}, test acc: {}, test balacc: {}'.format( \n",
    "                  epoch+1, np.mean(self.tr_loss), np.mean(self.test_loss), \n",
    "                  np.mean(self.train_accuracy), np.mean(self.train_bacc), np.mean(self.test_accuracy), np.mean(self.test_bacc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, classes):\n",
    "        super(FFNet, self).__init__()\n",
    "\n",
    "#         self.fc1 = torch.nn.Linear(input_size, 1000)\n",
    "#         self.relu1 = torch.nn.ReLU()\n",
    "#         self.drop1 = torch.nn.Dropout(0.5)\n",
    "#         self.bn1 = torch.nn.BatchNorm1d(1000)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(input_size, 500)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.drop2 = torch.nn.Dropout(0.5)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(500)\n",
    "\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(500, 250)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.drop3 = torch.nn.Dropout(0.5)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(250)\n",
    "\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(250, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.drop1(x)\n",
    "#         x = self.bn1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, classes):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden = 128\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=self.hidden,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(2*self.hidden, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFNet(input_size=input_size, classes=num_classes)\n",
    "opts = {\n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 4e-3,\n",
    "    'epochs': 5,\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "NetTrainer = TrainHelper(model = model,\n",
    "                      train_set = train_dataset,\n",
    "                      test_set = test_dataset,opts = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6899202b17684873a9906137ce9224ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1, train loss: 0.6318946224207849, test loss: 0.6630702537375611, train acc: 0.650807418196672, train balacc: 0.653068207200515, test acc: 0.6175595238095237, test balacc: 0.6452497978566363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b31eee173804252a848a5c7ef629032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2, train loss: 0.5715076502572897, test loss: 0.6514526117931713, train acc: 0.6766776535021715, train balacc: 0.6792495051261241, test acc: 0.6361268939393939, test balacc: 0.6478605169382246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbe4c5264714064bc96df30ea8bc697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3, train loss: 0.5317757364722722, test loss: 0.6332952391791653, train acc: 0.695833736437775, train balacc: 0.6986938788131897, test acc: 0.654795725108225, test balacc: 0.6462962349500475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70201c3479184748936e08dec325346c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4, train loss: 0.4975442058750875, test loss: 0.6251604636381198, train acc: 0.7112457069376963, train balacc: 0.714235376707883, test acc: 0.6746482683982684, test balacc: 0.6410978105963031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5c394e31d849d7a09e72ed3a0f11c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5, train loss: 0.4657990783869454, test loss: 0.592251432793481, train acc: 0.724827068194522, train balacc: 0.7279044362800793, test acc: 0.7105316558441559, test balacc: 0.6339830013734113\n"
     ]
    }
   ],
   "source": [
    "NetTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=10000, verbose=2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(max_iter=10000, verbose=2)\n",
    "clf.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 4906\n",
      "FP: 1003\n",
      "TN: 1684\n",
      "FN: 2247\n",
      "Accuracy: 0.6697154471544715\n",
      "BER: 0.34370633967722664\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "TP_ = np.logical_and(y_pred, y_val)\n",
    "FP_ = np.logical_and(y_pred, np.logical_not(y_val))\n",
    "TN_ = np.logical_and(np.logical_not(y_pred), np.logical_not(y_val))\n",
    "FN_ = np.logical_and(np.logical_not(y_pred), y_val)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'BER: {BER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 250\n",
      "building tree 2 of 250\n",
      "building tree 3 of 250\n",
      "building tree 4 of 250\n",
      "building tree 5 of 250\n",
      "building tree 6 of 250\n",
      "building tree 7 of 250\n",
      "building tree 8 of 250\n",
      "building tree 9 of 250\n",
      "building tree 10 of 250\n",
      "building tree 11 of 250\n",
      "building tree 12 of 250\n",
      "building tree 13 of 250\n",
      "building tree 14 of 250\n",
      "building tree 15 of 250\n",
      "building tree 16 of 250\n",
      "building tree 17 of 250\n",
      "building tree 18 of 250\n",
      "building tree 19 of 250\n",
      "building tree 20 of 250\n",
      "building tree 21 of 250\n",
      "building tree 22 of 250\n",
      "building tree 23 of 250\n",
      "building tree 24 of 250\n",
      "building tree 25 of 250\n",
      "building tree 26 of 250\n",
      "building tree 27 of 250\n",
      "building tree 28 of 250\n",
      "building tree 29 of 250\n",
      "building tree 30 of 250\n",
      "building tree 31 of 250\n",
      "building tree 32 of 250\n",
      "building tree 33 of 250building tree 34 of 250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  27 tasks      | elapsed:    1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 35 of 250\n",
      "building tree 36 of 250\n",
      "building tree 37 of 250\n",
      "building tree 38 of 250\n",
      "building tree 39 of 250\n",
      "building tree 40 of 250\n",
      "building tree 41 of 250\n",
      "building tree 42 of 250\n",
      "building tree 43 of 250\n",
      "building tree 44 of 250\n",
      "building tree 45 of 250\n",
      "building tree 46 of 250\n",
      "building tree 47 of 250\n",
      "building tree 48 of 250\n",
      "building tree 49 of 250\n",
      "building tree 50 of 250\n",
      "building tree 51 of 250\n",
      "building tree 52 of 250\n",
      "building tree 53 of 250\n",
      "building tree 54 of 250\n",
      "building tree 55 of 250\n",
      "building tree 56 of 250\n",
      "building tree 57 of 250\n",
      "building tree 58 of 250\n",
      "building tree 59 of 250\n",
      "building tree 60 of 250\n",
      "building tree 61 of 250\n",
      "building tree 62 of 250\n",
      "building tree 63 of 250\n",
      "building tree 64 of 250\n",
      "building tree 65 of 250\n",
      "building tree 66 of 250\n",
      "building tree 67 of 250\n",
      "building tree 68 of 250\n",
      "building tree 69 of 250\n",
      "building tree 70 of 250\n",
      "building tree 71 of 250\n",
      "building tree 72 of 250\n",
      "building tree 73 of 250\n",
      "building tree 74 of 250\n",
      "building tree 75 of 250\n",
      "building tree 76 of 250\n",
      "building tree 77 of 250\n",
      "building tree 78 of 250\n",
      "building tree 79 of 250\n",
      "building tree 80 of 250\n",
      "building tree 81 of 250\n",
      "building tree 82 of 250\n",
      "building tree 83 of 250\n",
      "building tree 84 of 250\n",
      "building tree 85 of 250\n",
      "building tree 86 of 250\n",
      "building tree 87 of 250\n",
      "building tree 88 of 250\n",
      "building tree 89 of 250\n",
      "building tree 90 of 250\n",
      "building tree 91 of 250\n",
      "building tree 92 of 250\n",
      "building tree 93 of 250\n",
      "building tree 94 of 250\n",
      "building tree 95 of 250\n",
      "building tree 96 of 250\n",
      "building tree 97 of 250\n",
      "building tree 98 of 250building tree 99 of 250\n",
      "\n",
      "building tree 100 of 250\n",
      "building tree 101 of 250\n",
      "building tree 102 of 250\n",
      "building tree 103 of 250\n",
      "building tree 104 of 250\n",
      "building tree 105 of 250\n",
      "building tree 106 of 250\n",
      "building tree 107 of 250\n",
      "building tree 108 of 250\n",
      "building tree 109 of 250\n",
      "building tree 110 of 250\n",
      "building tree 111 of 250\n",
      "building tree 112 of 250\n",
      "building tree 113 of 250\n",
      "building tree 114 of 250\n",
      "building tree 115 of 250\n",
      "building tree 116 of 250\n",
      "building tree 117 of 250\n",
      "building tree 118 of 250\n",
      "building tree 119 of 250\n",
      "building tree 120 of 250\n",
      "building tree 121 of 250\n",
      "building tree 122 of 250\n",
      "building tree 123 of 250\n",
      "building tree 124 of 250\n",
      "building tree 125 of 250\n",
      "building tree 126 of 250\n",
      "building tree 127 of 250\n",
      "building tree 128 of 250\n",
      "building tree 129 of 250\n",
      "building tree 130 of 250\n",
      "building tree 131 of 250\n",
      "building tree 132 of 250\n",
      "building tree 133 of 250\n",
      "building tree 134 of 250\n",
      "building tree 135 of 250\n",
      "building tree 136 of 250\n",
      "building tree 137 of 250\n",
      "building tree 138 of 250\n",
      "building tree 139 of 250\n",
      "building tree 140 of 250\n",
      "building tree 141 of 250\n",
      "building tree 142 of 250\n",
      "building tree 143 of 250\n",
      "building tree 144 of 250\n",
      "building tree 145 of 250\n",
      "building tree 146 of 250\n",
      "building tree 147 of 250\n",
      "building tree 148 of 250\n",
      "building tree 149 of 250\n",
      "building tree 150 of 250\n",
      "building tree 151 of 250\n",
      "building tree 152 of 250\n",
      "building tree 153 of 250\n",
      "building tree 154 of 250\n",
      "building tree 155 of 250\n",
      "building tree 156 of 250\n",
      "building tree 157 of 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:    8.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 158 of 250\n",
      "building tree 159 of 250\n",
      "building tree 160 of 250\n",
      "building tree 161 of 250\n",
      "building tree 162 of 250\n",
      "building tree 163 of 250building tree 164 of 250\n",
      "\n",
      "building tree 165 of 250\n",
      "building tree 166 of 250\n",
      "building tree 167 of 250\n",
      "building tree 168 of 250\n",
      "building tree 169 of 250\n",
      "building tree 170 of 250\n",
      "building tree 171 of 250\n",
      "building tree 172 of 250\n",
      "building tree 173 of 250\n",
      "building tree 174 of 250\n",
      "building tree 175 of 250\n",
      "building tree 176 of 250\n",
      "building tree 177 of 250\n",
      "building tree 178 of 250\n",
      "building tree 179 of 250\n",
      "building tree 180 of 250\n",
      "building tree 181 of 250\n",
      "building tree 182 of 250\n",
      "building tree 183 of 250\n",
      "building tree 184 of 250\n",
      "building tree 185 of 250\n",
      "building tree 186 of 250\n",
      "building tree 187 of 250\n",
      "building tree 188 of 250\n",
      "building tree 189 of 250\n",
      "building tree 190 of 250\n",
      "building tree 191 of 250\n",
      "building tree 192 of 250\n",
      "building tree 193 of 250\n",
      "building tree 194 of 250\n",
      "building tree 195 of 250\n",
      "building tree 196 of 250\n",
      "building tree 197 of 250\n",
      "building tree 198 of 250\n",
      "building tree 199 of 250\n",
      "building tree 200 of 250\n",
      "building tree 201 of 250\n",
      "building tree 202 of 250\n",
      "building tree 203 of 250\n",
      "building tree 204 of 250\n",
      "building tree 205 of 250\n",
      "building tree 206 of 250\n",
      "building tree 207 of 250\n",
      "building tree 208 of 250\n",
      "building tree 209 of 250\n",
      "building tree 210 of 250\n",
      "building tree 211 of 250\n",
      "building tree 212 of 250building tree 213 of 250\n",
      "\n",
      "building tree 214 of 250\n",
      "building tree 215 of 250\n",
      "building tree 216 of 250\n",
      "building tree 217 of 250\n",
      "building tree 218 of 250\n",
      "building tree 219 of 250\n",
      "building tree 220 of 250\n",
      "building tree 221 of 250\n",
      "building tree 222 of 250\n",
      "building tree 223 of 250\n",
      "building tree 224 of 250\n",
      "building tree 225 of 250\n",
      "building tree 226 of 250\n",
      "building tree 227 of 250\n",
      "building tree 228 of 250\n",
      "building tree 229 of 250\n",
      "building tree 230 of 250\n",
      "building tree 231 of 250\n",
      "building tree 232 of 250\n",
      "building tree 233 of 250\n",
      "building tree 234 of 250\n",
      "building tree 235 of 250\n",
      "building tree 236 of 250\n",
      "building tree 237 of 250\n",
      "building tree 238 of 250\n",
      "building tree 239 of 250\n",
      "building tree 240 of 250\n",
      "building tree 241 of 250\n",
      "building tree 242 of 250\n",
      "building tree 243 of 250\n",
      "building tree 244 of 250\n",
      "building tree 245 of 250\n",
      "building tree 246 of 250\n",
      "building tree 247 of 250\n",
      "building tree 248 of 250\n",
      "building tree 249 of 250\n",
      "building tree 250 of 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done 250 out of 250 | elapsed:   13.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features=15, max_leaf_nodes=100,\n",
       "                       min_samples_leaf=10, n_estimators=250, n_jobs=-2,\n",
       "                       verbose=2)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(max_features=15, max_depth=10, min_samples_leaf=10, max_leaf_nodes=100, n_estimators=250, verbose=2, n_jobs=-2)\n",
    "clf2.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 148 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 250 out of 250 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 6185\n",
      "FP: 2116\n",
      "TN: 571\n",
      "FN: 968\n",
      "Accuracy: 0.6865853658536586\n",
      "BAcc: 0.5385884087766194\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf2.predict(X_val)\n",
    "TP_ = np.logical_and(y_pred, y_val)\n",
    "FP_ = np.logical_and(y_pred, np.logical_not(y_val))\n",
    "TN_ = np.logical_and(np.logical_not(y_pred), np.logical_not(y_val))\n",
    "FN_ = np.logical_and(np.logical_not(y_pred), y_val)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "BAcc = 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'BAcc: {BAcc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad boost\n",
    "# Accuracy: 0.7267276422764227\n",
    "# BAcc: 0.6000076950648203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 148 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=7)]: Done 250 out of 250 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 50759\n",
      "FP: 20831\n",
      "TN: 36398\n",
      "FN: 6470\n",
      "Accuracy: 0.7614758251935208\n",
      "BAcc: 0.7614758251935208\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf2.predict(X_over)\n",
    "TP_ = np.logical_and(y_pred, y_over)\n",
    "FP_ = np.logical_and(y_pred, np.logical_not(y_over))\n",
    "TN_ = np.logical_and(np.logical_not(y_pred), np.logical_not(y_over))\n",
    "FN_ = np.logical_and(np.logical_not(y_pred), y_over)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "BAcc = 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'BAcc: {BAcc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'predict_aita_nn.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net(input_size=input_size, classes=num_classes)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
