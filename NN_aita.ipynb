{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tqdm import tqdm, notebook\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'aita_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ytr72</td>\n",
       "      <td>1.393275e+09</td>\n",
       "      <td>[AITA] Construction worker here</td>\n",
       "      <td>I have been on a parking structure project for...</td>\n",
       "      <td>False</td>\n",
       "      <td>too close to call</td>\n",
       "      <td>63</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>1.393279e+09</td>\n",
       "      <td>[AITA] I wrote an explanation in TIL and came ...</td>\n",
       "      <td>[Here is the post in question](http://www.redd...</td>\n",
       "      <td>False</td>\n",
       "      <td>asshole</td>\n",
       "      <td>52</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>1.393281e+09</td>\n",
       "      <td>[AITA] Threw my parent's donuts away</td>\n",
       "      <td>My parents are diabetic, morbidly obese, and a...</td>\n",
       "      <td>1393290576.0</td>\n",
       "      <td>asshole</td>\n",
       "      <td>140</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yu41e</td>\n",
       "      <td>1.393282e+09</td>\n",
       "      <td>[AITA] I Put My Empty Beer on a Bar Table</td>\n",
       "      <td>Relevant Facts:\\n\\n1) It was a crowded bar, th...</td>\n",
       "      <td>False</td>\n",
       "      <td>nothing happened</td>\n",
       "      <td>45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>1.393285e+09</td>\n",
       "      <td>I told a goth girl she looked like a clown.</td>\n",
       "      <td>I was four.</td>\n",
       "      <td>False</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167755</th>\n",
       "      <td>ex970f</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>AITA for telling my husband to f* off after he...</td>\n",
       "      <td>My husband (28M) and I (32F) are married for a...</td>\n",
       "      <td>1580584475.0</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>1373</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167756</th>\n",
       "      <td>ex97ye</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>AITA for refusing to give my ticket to my brot...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>False</td>\n",
       "      <td>no a-holes here</td>\n",
       "      <td>4</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167758</th>\n",
       "      <td>ex9dwo</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>AITA for attempting to keep my students out of...</td>\n",
       "      <td>Upfront apologies for formatting. I’m also try...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167759</th>\n",
       "      <td>ex9egs</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>WIBTA if I left my brothers fate up to the state?</td>\n",
       "      <td>A little back story my mom is a drug addict an...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>280</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167760</th>\n",
       "      <td>ex9g78</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>WIBTA for rocking the boat at work because my ...</td>\n",
       "      <td>I’m a (23F) apprentice in the trades. I work o...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>5</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129953 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     timestamp  \\\n",
       "0       1ytr72  1.393275e+09   \n",
       "1       1ytxov  1.393279e+09   \n",
       "2       1yu29c  1.393281e+09   \n",
       "3       1yu41e  1.393282e+09   \n",
       "4       1yu8hi  1.393285e+09   \n",
       "...        ...           ...   \n",
       "167755  ex970f  1.580577e+09   \n",
       "167756  ex97ye  1.580577e+09   \n",
       "167758  ex9dwo  1.580578e+09   \n",
       "167759  ex9egs  1.580578e+09   \n",
       "167760  ex9g78  1.580578e+09   \n",
       "\n",
       "                                                    title  \\\n",
       "0                         [AITA] Construction worker here   \n",
       "1       [AITA] I wrote an explanation in TIL and came ...   \n",
       "2                    [AITA] Threw my parent's donuts away   \n",
       "3               [AITA] I Put My Empty Beer on a Bar Table   \n",
       "4             I told a goth girl she looked like a clown.   \n",
       "...                                                   ...   \n",
       "167755  AITA for telling my husband to f* off after he...   \n",
       "167756  AITA for refusing to give my ticket to my brot...   \n",
       "167758  AITA for attempting to keep my students out of...   \n",
       "167759  WIBTA if I left my brothers fate up to the state?   \n",
       "167760  WIBTA for rocking the boat at work because my ...   \n",
       "\n",
       "                                                     body        edited  \\\n",
       "0       I have been on a parking structure project for...         False   \n",
       "1       [Here is the post in question](http://www.redd...         False   \n",
       "2       My parents are diabetic, morbidly obese, and a...  1393290576.0   \n",
       "3       Relevant Facts:\\n\\n1) It was a crowded bar, th...         False   \n",
       "4                                             I was four.         False   \n",
       "...                                                   ...           ...   \n",
       "167755  My husband (28M) and I (32F) are married for a...  1580584475.0   \n",
       "167756                                          [deleted]         False   \n",
       "167758  Upfront apologies for formatting. I’m also try...         False   \n",
       "167759  A little back story my mom is a drug addict an...         False   \n",
       "167760  I’m a (23F) apprentice in the trades. I work o...         False   \n",
       "\n",
       "                  verdict  score  num_comments  \n",
       "0       too close to call     63           9.0  \n",
       "1                 asshole     52          13.0  \n",
       "2                 asshole    140          27.0  \n",
       "3        nothing happened     45           7.0  \n",
       "4         not the asshole     74          15.0  \n",
       "...                   ...    ...           ...  \n",
       "167755     not the a-hole   1373         304.0  \n",
       "167756    no a-holes here      4          16.0  \n",
       "167758     not the a-hole      4          15.0  \n",
       "167759     not the a-hole    280         140.0  \n",
       "167760     not the a-hole      5          21.0  \n",
       "\n",
       "[129953 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(axis=0)\n",
    "df['verdict'] = df['verdict'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not the a-hole      75393\n",
      "asshole             27449\n",
      "no a-holes here     15129\n",
      "everyone sucks       7417\n",
      "not enough info      2713\n",
      "                    ...  \n",
      "nothing happened        1\n",
      "really??                1\n",
      "10% asshole             1\n",
      "not the a-hole-         1\n",
      "inconclusive            1\n",
      "Name: verdict, Length: 410, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df['verdict'].value_counts()\n",
    "print(counts)\n",
    "v = df['verdict']\n",
    "df = df[v.replace(counts.gt(300))]\n",
    "replace_dict = {\n",
    "    'not the asshole': 'not the a-hole',\n",
    "    'no a--holes here': 'no a-holes here'\n",
    "}\n",
    "df = df.replace({'verdict': replace_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole     75766\n",
       "asshole            27449\n",
       "no a-holes here    15432\n",
       "everyone sucks      7417\n",
       "not enough info     2713\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole    91198\n",
       "asshole           34866\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = df['verdict']\n",
    "df = df[v.replace(counts.gt(3000))]\n",
    "replace_dict = {\n",
    "    'no a-holes here': 'not the a-hole',\n",
    "    'everyone sucks': 'asshole'\n",
    "}\n",
    "df = df.replace({'verdict': replace_dict})\n",
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole    71536\n",
       "asshole           26863\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = df['body']\n",
    "df = df[v != '[deleted]']\n",
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asshole' 'not the a-hole']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "verdicts = df['verdict'].unique()\n",
    "print(verdicts)\n",
    "num_classes = len(verdicts)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    ignore_tokens = string.punctuation\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) \n",
    "                if not any(i in t for i in self.ignore_tokens) and len(t) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['edited'] = [0 if 'false' in d else 1 for d in df['edited'].str.lower() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_comments'] = np.log(df['num_comments'])\n",
    "df['score'] = np.log(df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['body'] = df['body'].str.lower() # convert to lowercase\n",
    "df['title'] = df['title'].str.lower() # convert to lowercase\n",
    "df['body'] = df[['title', 'body']].agg(' '.join, axis=1)\n",
    "\n",
    "df['body'] = df['body'].str.replace('[^\\w\\s]', ' ') # replace characters that are not alphanumeric or spaces\n",
    "# df['body'] = df['body'].str.replace('\\d+', '') # replace numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>1.393279e+09</td>\n",
       "      <td>[aita] i wrote an explanation in til and came ...</td>\n",
       "      <td>aita  i wrote an explanation in til and came ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>2.564949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>1.393281e+09</td>\n",
       "      <td>[aita] threw my parent's donuts away</td>\n",
       "      <td>aita  threw my parent s donuts away my parent...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.941642</td>\n",
       "      <td>3.295837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>1.393285e+09</td>\n",
       "      <td>i told a goth girl she looked like a clown.</td>\n",
       "      <td>i told a goth girl she looked like a clown  i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1yuc78</td>\n",
       "      <td>1.393287e+09</td>\n",
       "      <td>[aita]: argument i had with another redditor i...</td>\n",
       "      <td>aita   argument i had with another redditor i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1yugsc</td>\n",
       "      <td>1.393289e+09</td>\n",
       "      <td>aita had a disagreement about les miserables w...</td>\n",
       "      <td>aita had a disagreement about les miserables w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167754</th>\n",
       "      <td>ex94w5</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>aita for telling my sister she is being a spoi...</td>\n",
       "      <td>aita for telling my sister she is being a spoi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>3.135494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167755</th>\n",
       "      <td>ex970f</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>aita for telling my husband to f* off after he...</td>\n",
       "      <td>aita for telling my husband to f  off after he...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.224753</td>\n",
       "      <td>5.717028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167758</th>\n",
       "      <td>ex9dwo</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>aita for attempting to keep my students out of...</td>\n",
       "      <td>aita for attempting to keep my students out of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167759</th>\n",
       "      <td>ex9egs</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>wibta if i left my brothers fate up to the state?</td>\n",
       "      <td>wibta if i left my brothers fate up to the sta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.634790</td>\n",
       "      <td>4.941642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167760</th>\n",
       "      <td>ex9g78</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>wibta for rocking the boat at work because my ...</td>\n",
       "      <td>wibta for rocking the boat at work because my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.044522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98399 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     timestamp  \\\n",
       "1       1ytxov  1.393279e+09   \n",
       "2       1yu29c  1.393281e+09   \n",
       "4       1yu8hi  1.393285e+09   \n",
       "5       1yuc78  1.393287e+09   \n",
       "7       1yugsc  1.393289e+09   \n",
       "...        ...           ...   \n",
       "167754  ex94w5  1.580577e+09   \n",
       "167755  ex970f  1.580577e+09   \n",
       "167758  ex9dwo  1.580578e+09   \n",
       "167759  ex9egs  1.580578e+09   \n",
       "167760  ex9g78  1.580578e+09   \n",
       "\n",
       "                                                    title  \\\n",
       "1       [aita] i wrote an explanation in til and came ...   \n",
       "2                    [aita] threw my parent's donuts away   \n",
       "4             i told a goth girl she looked like a clown.   \n",
       "5       [aita]: argument i had with another redditor i...   \n",
       "7       aita had a disagreement about les miserables w...   \n",
       "...                                                   ...   \n",
       "167754  aita for telling my sister she is being a spoi...   \n",
       "167755  aita for telling my husband to f* off after he...   \n",
       "167758  aita for attempting to keep my students out of...   \n",
       "167759  wibta if i left my brothers fate up to the state?   \n",
       "167760  wibta for rocking the boat at work because my ...   \n",
       "\n",
       "                                                     body  edited  verdict  \\\n",
       "1        aita  i wrote an explanation in til and came ...       0        0   \n",
       "2        aita  threw my parent s donuts away my parent...       1        0   \n",
       "4       i told a goth girl she looked like a clown  i ...       0        1   \n",
       "5        aita   argument i had with another redditor i...       1        0   \n",
       "7       aita had a disagreement about les miserables w...       0        0   \n",
       "...                                                   ...     ...      ...   \n",
       "167754  aita for telling my sister she is being a spoi...       1        1   \n",
       "167755  aita for telling my husband to f  off after he...       1        1   \n",
       "167758  aita for attempting to keep my students out of...       0        1   \n",
       "167759  wibta if i left my brothers fate up to the sta...       0        1   \n",
       "167760  wibta for rocking the boat at work because my ...       0        1   \n",
       "\n",
       "           score  num_comments  \n",
       "1       3.951244      2.564949  \n",
       "2       4.941642      3.295837  \n",
       "4       4.304065      2.708050  \n",
       "5       3.091042      1.098612  \n",
       "7       3.091042      2.708050  \n",
       "...          ...           ...  \n",
       "167754  2.772589      3.135494  \n",
       "167755  7.224753      5.717028  \n",
       "167758  1.386294      2.708050  \n",
       "167759  5.634790      4.941642  \n",
       "167760  1.609438      3.044522  \n",
       "\n",
       "[98399 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df['verdict'].unique()\n",
    "verdict_map = dict(zip(classes, range(len(classes))))\n",
    "df['verdict'] = df['verdict'].replace(verdict_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_temp = train_test_split(df, test_size=0.2, stratify=df['verdict'])\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp['verdict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = df_train[['edited', 'score', 'num_comments']].to_numpy()\n",
    "labels = df_train['verdict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=LemmaTokenizer()\n",
    "word_list = ['aita']\n",
    "\n",
    "stop_words = set(ENGLISH_STOP_WORDS.union(word_list))\n",
    "tokenized_stop = tokenizer(' '.join(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78719, 1000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, sublinear_tf=True, max_df=0.95, \n",
    "                             min_df=5, ngram_range=(1, 2), tokenizer=tokenizer, stop_words=tokenized_stop)\n",
    "# vectorizer = TfidfVectorizer(max_features=1000, sublinear_tf=True, max_df=0.95, \n",
    "#                              min_df=5, ngram_range=(1, 2))\n",
    "text_features = vectorizer.fit_transform(df_train['body']).toarray()\n",
    "print(text_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names = ['edited', 'score', 'num_comments'] + feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2314.88 MiB, increment: -0.43 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78719, 1003)\n"
     ]
    }
   ],
   "source": [
    "text_features = np.array(np.hstack((transformed_data, text_features)))\n",
    "print(text_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2317.25 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n",
      "(78719, 1003)\n",
      "(78719,)\n"
     ]
    }
   ],
   "source": [
    "X_train = text_features\n",
    "y_train = np.array(labels)\n",
    "input_size = len(X_train[0])\n",
    "print(input_size)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42980, 1003)\n",
      "(42980,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_under, y_under = rus.fit_resample(X_train, y_train)\n",
    "print(X_under.shape)\n",
    "print(y_under.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114458, 1003)\n",
      "(114458,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=0)\n",
    "X_over, y_over = sm.fit_resample(X_train, y_train)\n",
    "print(X_over.shape)\n",
    "print(y_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=500, score_func=<function chi2 at 0x7fa64c1c2710>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_rank = SelectKBest(chi2, k=500)\n",
    "feature_rank.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = []\n",
    "for i, (score, feature) in enumerate(zip(feature_rank.scores_, feature_names)):\n",
    "    feat.append((score, feature))\n",
    "    \n",
    "dfObj = pd.DataFrame(feat, columns = ['chi_squared', 'word']) \n",
    "dfObj.sort_values(by=['chi_squared'], ascending = False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 1003)\n",
      "(9840,)\n"
     ]
    }
   ],
   "source": [
    "transformed_val = df_val[['edited', 'score', 'num_comments']].to_numpy()\n",
    "labels_val = df_val['verdict']\n",
    "X_val = np.array(np.hstack((transformed_val, vectorizer.transform(df_val['body']).toarray())))\n",
    "y_val = np.array(labels_val)\n",
    "del transformed_val\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3602.26 MiB, increment: -2.20 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process = make_pipeline(PowerTransformer(method='yeo-johnson'))\n",
    "# ct = ColumnTransformer([(\"power\", process, [x for x in range(0, 6)])], remainder='passthrough')\n",
    "# X_train = ct.fit_transform(X_train)\n",
    "# X_test = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3602.26 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(Variable(torch.from_numpy(X_over.astype(np.float32))), \n",
    "                                   Variable(torch.from_numpy(y_over.astype(np.long))))\n",
    "test_dataset = Data.TensorDataset(Variable(torch.from_numpy(X_val.astype(np.float32))), \n",
    "                                  Variable(torch.from_numpy(y_val.astype(np.long))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainHelper():\n",
    "    '''\n",
    "    Helper class that makes it a bit easier and cleaner to define the training routine\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,model,train_set,test_set,opts):\n",
    "        self.model = model \n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.epochs = opts['epochs']\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=opts['lr'], weight_decay=opts['weight_decay']) # optimizer method for gradient descent\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()                      # loss function\n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                                        batch_size=opts['batch_size'],\n",
    "                                                        shuffle=True)\n",
    "        self.test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                                       batch_size=opts['batch_size'],\n",
    "                                                       shuffle=True)\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.train() #put model in training mode\n",
    "        self.train_accuracy = []\n",
    "        self.train_bacc = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.tr_loss = []\n",
    "            for i, (data,labels) in notebook.tqdm(enumerate(self.train_loader),\n",
    "                                                   total = len(self.train_loader)):\n",
    "                self.model.train()\n",
    "                data, labels = data.to(self.device),labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(data)  \n",
    "                loss = self.criterion(outputs, labels) \n",
    "                loss.backward()                        \n",
    "                self.optimizer.step()                  \n",
    "                self.tr_loss.append(loss.item())\n",
    "                y_pred_softmax = torch.log_softmax(outputs.data, dim = 1)\n",
    "                _, predicted = torch.max(y_pred_softmax, dim = 1)\n",
    "#                 self.train_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
    "                self.train_accuracy.append(accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "                self.train_bacc.append(balanced_accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "\n",
    "            \n",
    "            self.test(epoch) # run through the validation set\n",
    "        \n",
    "    def test(self,epoch):\n",
    "            \n",
    "            self.model.eval()    # puts model in eval mode - not necessary for this demo but good to know\n",
    "            self.test_loss = []\n",
    "            self.test_accuracy = []\n",
    "            self.test_bacc = []\n",
    "\n",
    "            \n",
    "            for i, (data, labels) in enumerate(self.test_loader):\n",
    "                \n",
    "                data, labels = data.to(self.device),labels.to(self.device)\n",
    "                \n",
    "                # pass data through network\n",
    "                # turn off gradient calculation to speed up calcs and reduce memory\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(data)\n",
    "                \n",
    "                # make our predictions and update our loss info\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                self.test_loss.append(loss.item())\n",
    "                y_pred_softmax = torch.log_softmax(outputs.data, dim = 1)\n",
    "                _, predicted = torch.max(y_pred_softmax, dim = 1)\n",
    "                self.test_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
    "#                 self.test_accuracy.append(accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "                self.test_bacc.append(balanced_accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "\n",
    "            \n",
    "            print('epoch: {}, train loss: {}, test loss: {}, train acc: {}, train balacc: {}, test acc: {}, test balacc: {}'.format( \n",
    "                  epoch+1, np.mean(self.tr_loss), np.mean(self.test_loss), \n",
    "                  np.mean(self.train_accuracy), np.mean(self.train_bacc), np.mean(self.test_accuracy), np.mean(self.test_bacc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, classes):\n",
    "        super(FFNet, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(input_size, 2000)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.drop1 = torch.nn.Dropout(0.8)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(2000)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(2000, 1000)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.drop2 = torch.nn.Dropout(0.5)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(1000)\n",
    "\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(1000, 500)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.drop3 = torch.nn.Dropout(0.2)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(500)\n",
    "\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(500, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, classes):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden = 512\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=self.hidden,\n",
    "                            num_layers=5,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc = nn.Linear(2*self.hidden, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMNet(input_size=input_size, classes=num_classes)\n",
    "opts = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 4e-3,\n",
    "    'epochs': 5,\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "NetTrainer = TrainHelper(model = model,\n",
    "                      train_set = train_dataset,\n",
    "                      test_set = test_dataset,opts = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1b380e51764f208fe5080970f53037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1, train loss: 0.6012845247101024, test loss: 0.576484852409982, train acc: 0.6727819849937653, train balacc: 0.6729406601589772, test acc: 0.7014001623376623, test balacc: 0.6617217493222931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f65d8b055b74d90b393387d7e500536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2, train loss: 0.5766337896406217, test loss: 0.573995803664257, train acc: 0.6856470632497743, train balacc: 0.685736341556368, test acc: 0.7017045454545454, test balacc: 0.6643592812917474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b599881262240c6a6eed6f7cf95d56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3, train loss: 0.5643656279469016, test loss: 0.6002268733142259, train acc: 0.6917283416462428, train balacc: 0.6917504408176268, test acc: 0.6661255411255412, test balacc: 0.66591589712729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4071c3993b1440f4882042a12f704944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4, train loss: 0.556036859450892, test loss: 0.6226311616309277, train acc: 0.6955992080341403, train balacc: 0.6955252586261731, test acc: 0.670319264069264, test balacc: 0.6689484220268292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9fdf5d5df642c896a4aac4589b0af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5, train loss: 0.5497659809966537, test loss: 0.6004863619417339, train acc: 0.6983267134626134, train balacc: 0.6982883716630401, test acc: 0.6856737012987013, test balacc: 0.667895119086809\n"
     ]
    }
   ],
   "source": [
    "NetTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-3bc682e26028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_over\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_over\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1417\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    758\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m             )\n\u001b[1;32m    762\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Case where we fit the intercept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight='balanced', max_iter=10000, verbose=2)\n",
    "clf.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "TP_ = np.logical_and(y_pred, y_val)\n",
    "FP_ = np.logical_and(y_pred, np.logical_not(y_val))\n",
    "TN_ = np.logical_and(np.logical_not(y_pred), np.logical_not(y_val))\n",
    "FN_ = np.logical_and(np.logical_not(y_pred), y_val)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'BER: {BER}')\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(verbose=2)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "TP_ = np.logical_and(y_pred, y_val)\n",
    "FP_ = np.logical_and(y_pred, np.logical_not(y_val))\n",
    "TN_ = np.logical_and(np.logical_not(y_pred), np.logical_not(y_val))\n",
    "FN_ = np.logical_and(np.logical_not(y_pred), y_val)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'BER: {BER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'predict_aita_nn.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net(input_size=input_size, classes=num_classes)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
