{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tqdm import tqdm, notebook\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'aita_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ytr72</td>\n",
       "      <td>1.393275e+09</td>\n",
       "      <td>[AITA] Construction worker here</td>\n",
       "      <td>I have been on a parking structure project for...</td>\n",
       "      <td>False</td>\n",
       "      <td>too close to call</td>\n",
       "      <td>63</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>1.393279e+09</td>\n",
       "      <td>[AITA] I wrote an explanation in TIL and came ...</td>\n",
       "      <td>[Here is the post in question](http://www.redd...</td>\n",
       "      <td>False</td>\n",
       "      <td>asshole</td>\n",
       "      <td>52</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>1.393281e+09</td>\n",
       "      <td>[AITA] Threw my parent's donuts away</td>\n",
       "      <td>My parents are diabetic, morbidly obese, and a...</td>\n",
       "      <td>1393290576.0</td>\n",
       "      <td>asshole</td>\n",
       "      <td>140</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yu41e</td>\n",
       "      <td>1.393282e+09</td>\n",
       "      <td>[AITA] I Put My Empty Beer on a Bar Table</td>\n",
       "      <td>Relevant Facts:\\n\\n1) It was a crowded bar, th...</td>\n",
       "      <td>False</td>\n",
       "      <td>nothing happened</td>\n",
       "      <td>45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>1.393285e+09</td>\n",
       "      <td>I told a goth girl she looked like a clown.</td>\n",
       "      <td>I was four.</td>\n",
       "      <td>False</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167755</th>\n",
       "      <td>ex970f</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>AITA for telling my husband to f* off after he...</td>\n",
       "      <td>My husband (28M) and I (32F) are married for a...</td>\n",
       "      <td>1580584475.0</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>1373</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167756</th>\n",
       "      <td>ex97ye</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>AITA for refusing to give my ticket to my brot...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>False</td>\n",
       "      <td>no a-holes here</td>\n",
       "      <td>4</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167758</th>\n",
       "      <td>ex9dwo</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>AITA for attempting to keep my students out of...</td>\n",
       "      <td>Upfront apologies for formatting. I’m also try...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167759</th>\n",
       "      <td>ex9egs</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>WIBTA if I left my brothers fate up to the state?</td>\n",
       "      <td>A little back story my mom is a drug addict an...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>280</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167760</th>\n",
       "      <td>ex9g78</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>WIBTA for rocking the boat at work because my ...</td>\n",
       "      <td>I’m a (23F) apprentice in the trades. I work o...</td>\n",
       "      <td>False</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>5</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129953 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     timestamp  \\\n",
       "0       1ytr72  1.393275e+09   \n",
       "1       1ytxov  1.393279e+09   \n",
       "2       1yu29c  1.393281e+09   \n",
       "3       1yu41e  1.393282e+09   \n",
       "4       1yu8hi  1.393285e+09   \n",
       "...        ...           ...   \n",
       "167755  ex970f  1.580577e+09   \n",
       "167756  ex97ye  1.580577e+09   \n",
       "167758  ex9dwo  1.580578e+09   \n",
       "167759  ex9egs  1.580578e+09   \n",
       "167760  ex9g78  1.580578e+09   \n",
       "\n",
       "                                                    title  \\\n",
       "0                         [AITA] Construction worker here   \n",
       "1       [AITA] I wrote an explanation in TIL and came ...   \n",
       "2                    [AITA] Threw my parent's donuts away   \n",
       "3               [AITA] I Put My Empty Beer on a Bar Table   \n",
       "4             I told a goth girl she looked like a clown.   \n",
       "...                                                   ...   \n",
       "167755  AITA for telling my husband to f* off after he...   \n",
       "167756  AITA for refusing to give my ticket to my brot...   \n",
       "167758  AITA for attempting to keep my students out of...   \n",
       "167759  WIBTA if I left my brothers fate up to the state?   \n",
       "167760  WIBTA for rocking the boat at work because my ...   \n",
       "\n",
       "                                                     body        edited  \\\n",
       "0       I have been on a parking structure project for...         False   \n",
       "1       [Here is the post in question](http://www.redd...         False   \n",
       "2       My parents are diabetic, morbidly obese, and a...  1393290576.0   \n",
       "3       Relevant Facts:\\n\\n1) It was a crowded bar, th...         False   \n",
       "4                                             I was four.         False   \n",
       "...                                                   ...           ...   \n",
       "167755  My husband (28M) and I (32F) are married for a...  1580584475.0   \n",
       "167756                                          [deleted]         False   \n",
       "167758  Upfront apologies for formatting. I’m also try...         False   \n",
       "167759  A little back story my mom is a drug addict an...         False   \n",
       "167760  I’m a (23F) apprentice in the trades. I work o...         False   \n",
       "\n",
       "                  verdict  score  num_comments  \n",
       "0       too close to call     63           9.0  \n",
       "1                 asshole     52          13.0  \n",
       "2                 asshole    140          27.0  \n",
       "3        nothing happened     45           7.0  \n",
       "4         not the asshole     74          15.0  \n",
       "...                   ...    ...           ...  \n",
       "167755     not the a-hole   1373         304.0  \n",
       "167756    no a-holes here      4          16.0  \n",
       "167758     not the a-hole      4          15.0  \n",
       "167759     not the a-hole    280         140.0  \n",
       "167760     not the a-hole      5          21.0  \n",
       "\n",
       "[129953 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(axis=0)\n",
    "df['verdict'] = df['verdict'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not the a-hole               75393\n",
      "asshole                      27449\n",
      "no a-holes here              15129\n",
      "everyone sucks                7417\n",
      "not enough info               2713\n",
      "                             ...  \n",
      "no assholes - yet                1\n",
      "inconclusive                     1\n",
      "definitely not the a-hole        1\n",
      "cool meta                        1\n",
      " unanimassly the asshole         1\n",
      "Name: verdict, Length: 410, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df['verdict'].value_counts()\n",
    "print(counts)\n",
    "v = df['verdict']\n",
    "df = df[v.replace(counts.gt(300))]\n",
    "replace_dict = {\n",
    "    'not the asshole': 'not the a-hole',\n",
    "    'no a--holes here': 'no a-holes here'\n",
    "}\n",
    "df = df.replace({'verdict': replace_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole     75766\n",
       "asshole            27449\n",
       "no a-holes here    15432\n",
       "everyone sucks      7417\n",
       "not enough info     2713\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole    91198\n",
       "asshole           34866\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = df['verdict']\n",
    "df = df[v.replace(counts.gt(3000))]\n",
    "replace_dict = {\n",
    "    'no a-holes here': 'not the a-hole',\n",
    "    'everyone sucks': 'asshole'\n",
    "}\n",
    "df = df.replace({'verdict': replace_dict})\n",
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not the a-hole    71536\n",
       "asshole           26863\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = df['body']\n",
    "df = df[v != '[deleted]']\n",
    "df['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asshole' 'not the a-hole']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "verdicts = df['verdict'].unique()\n",
    "print(verdicts)\n",
    "num_classes = len(verdicts)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    ignore_tokens = string.punctuation\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) \n",
    "                if not any(i in t for i in self.ignore_tokens) and len(t) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['edited'] = [0 if 'false' in d else 1 for d in df['edited'].str.lower() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_comments'] = df['num_comments'].astype(int)\n",
    "df['score'] = df['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['body'] = df['body'].str.lower() # convert to lowercase\n",
    "df['title'] = df['title'].str.lower() # convert to lowercase\n",
    "df['body'] = df[['title', 'body']].agg(' '.join, axis=1)\n",
    "\n",
    "df['body'] = df['body'].str.replace('[^\\w\\s]', ' ') # replace characters that are not alphanumeric or spaces\n",
    "# df['body'] = df['body'].str.replace('\\d+', '') # replace numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>1.393279e+09</td>\n",
       "      <td>[aita] i wrote an explanation in til and came ...</td>\n",
       "      <td>aita  i wrote an explanation in til and came ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>1.393281e+09</td>\n",
       "      <td>[aita] threw my parent's donuts away</td>\n",
       "      <td>aita  threw my parent s donuts away my parent...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>1.393285e+09</td>\n",
       "      <td>i told a goth girl she looked like a clown.</td>\n",
       "      <td>i told a goth girl she looked like a clown  i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1yuc78</td>\n",
       "      <td>1.393287e+09</td>\n",
       "      <td>[aita]: argument i had with another redditor i...</td>\n",
       "      <td>aita   argument i had with another redditor i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1yugsc</td>\n",
       "      <td>1.393289e+09</td>\n",
       "      <td>aita had a disagreement about les miserables w...</td>\n",
       "      <td>aita had a disagreement about les miserables w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167754</th>\n",
       "      <td>ex94w5</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>aita for telling my sister she is being a spoi...</td>\n",
       "      <td>aita for telling my sister she is being a spoi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167755</th>\n",
       "      <td>ex970f</td>\n",
       "      <td>1.580577e+09</td>\n",
       "      <td>aita for telling my husband to f* off after he...</td>\n",
       "      <td>aita for telling my husband to f  off after he...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167758</th>\n",
       "      <td>ex9dwo</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>aita for attempting to keep my students out of...</td>\n",
       "      <td>aita for attempting to keep my students out of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167759</th>\n",
       "      <td>ex9egs</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>wibta if i left my brothers fate up to the state?</td>\n",
       "      <td>wibta if i left my brothers fate up to the sta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167760</th>\n",
       "      <td>ex9g78</td>\n",
       "      <td>1.580578e+09</td>\n",
       "      <td>wibta for rocking the boat at work because my ...</td>\n",
       "      <td>wibta for rocking the boat at work because my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98399 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     timestamp  \\\n",
       "1       1ytxov  1.393279e+09   \n",
       "2       1yu29c  1.393281e+09   \n",
       "4       1yu8hi  1.393285e+09   \n",
       "5       1yuc78  1.393287e+09   \n",
       "7       1yugsc  1.393289e+09   \n",
       "...        ...           ...   \n",
       "167754  ex94w5  1.580577e+09   \n",
       "167755  ex970f  1.580577e+09   \n",
       "167758  ex9dwo  1.580578e+09   \n",
       "167759  ex9egs  1.580578e+09   \n",
       "167760  ex9g78  1.580578e+09   \n",
       "\n",
       "                                                    title  \\\n",
       "1       [aita] i wrote an explanation in til and came ...   \n",
       "2                    [aita] threw my parent's donuts away   \n",
       "4             i told a goth girl she looked like a clown.   \n",
       "5       [aita]: argument i had with another redditor i...   \n",
       "7       aita had a disagreement about les miserables w...   \n",
       "...                                                   ...   \n",
       "167754  aita for telling my sister she is being a spoi...   \n",
       "167755  aita for telling my husband to f* off after he...   \n",
       "167758  aita for attempting to keep my students out of...   \n",
       "167759  wibta if i left my brothers fate up to the state?   \n",
       "167760  wibta for rocking the boat at work because my ...   \n",
       "\n",
       "                                                     body  edited  verdict  \\\n",
       "1        aita  i wrote an explanation in til and came ...       0        0   \n",
       "2        aita  threw my parent s donuts away my parent...       1        0   \n",
       "4       i told a goth girl she looked like a clown  i ...       0        1   \n",
       "5        aita   argument i had with another redditor i...       1        0   \n",
       "7       aita had a disagreement about les miserables w...       0        0   \n",
       "...                                                   ...     ...      ...   \n",
       "167754  aita for telling my sister she is being a spoi...       1        1   \n",
       "167755  aita for telling my husband to f  off after he...       1        1   \n",
       "167758  aita for attempting to keep my students out of...       0        1   \n",
       "167759  wibta if i left my brothers fate up to the sta...       0        1   \n",
       "167760  wibta for rocking the boat at work because my ...       0        1   \n",
       "\n",
       "        score  num_comments  \n",
       "1          52            13  \n",
       "2         140            27  \n",
       "4          74            15  \n",
       "5          22             3  \n",
       "7          22            15  \n",
       "...       ...           ...  \n",
       "167754     16            23  \n",
       "167755   1373           304  \n",
       "167758      4            15  \n",
       "167759    280           140  \n",
       "167760      5            21  \n",
       "\n",
       "[98399 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df['verdict'].unique()\n",
    "verdict_map = dict(zip(classes, range(len(classes))))\n",
    "df['verdict'] = df['verdict'].replace(verdict_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_temp = train_test_split(df, test_size=0.2, stratify=df['verdict'])\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp['verdict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = df_train[['edited', 'score', 'num_comments']].to_numpy()\n",
    "labels = df_train['verdict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=LemmaTokenizer()\n",
    "word_list = ['aita']\n",
    "\n",
    "stop_words = set(ENGLISH_STOP_WORDS.union(word_list))\n",
    "tokenized_stop = tokenizer(' '.join(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78719, 1000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, sublinear_tf=True, max_df=0.95, \n",
    "                             min_df=5, ngram_range=(1, 1), tokenizer=tokenizer, stop_words=tokenized_stop)\n",
    "text_features = vectorizer.fit_transform(df_train['body']).toarray()\n",
    "print(text_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1710.35 MiB, increment: -0.43 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78719, 1003)\n"
     ]
    }
   ],
   "source": [
    "text_features = np.array(np.hstack((transformed_data, text_features)))\n",
    "print(text_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1712.36 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n",
      "(78719, 1003)\n",
      "(78719,)\n"
     ]
    }
   ],
   "source": [
    "X_train = text_features\n",
    "y_train = np.array(labels)\n",
    "input_size = len(X_train[0])\n",
    "print(input_size)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42980, 1003)\n",
      "(42980,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_under, y_under = rus.fit_resample(X_train, y_train)\n",
    "print(X_under.shape)\n",
    "print(y_under.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114458, 1003)\n",
      "(114458,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=0)\n",
    "X_over, y_over = sm.fit_resample(X_train, y_train)\n",
    "print(X_over.shape)\n",
    "print(y_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=500, score_func=<function chi2 at 0x7f8550e8e710>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_rank = SelectKBest(chi2, k=500)\n",
    "feature_rank.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186927.561263</td>\n",
       "      <td>absolutely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136466.176723</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>511.470270</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>66.289709</td>\n",
       "      <td>emotional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>52.331517</td>\n",
       "      <td>reply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.000097</td>\n",
       "      <td>position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>wearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>cleaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           1\n",
       "2    186927.561263  absolutely\n",
       "1    136466.176723        able\n",
       "0       511.470270         100\n",
       "272      66.289709   emotional\n",
       "714      52.331517       reply\n",
       "..             ...         ...\n",
       "663       0.000097    position\n",
       "956       0.000038     wearing\n",
       "562       0.000013        mind\n",
       "156       0.000006    cleaning\n",
       "951       0.000004       watch\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = []\n",
    "for i, (score, feature) in enumerate(zip(feature_rank.scores_, feature_names)):\n",
    "    feat.append((score, feature))\n",
    "    \n",
    "dfObj = pd.DataFrame(feat) \n",
    "dfObj.sort_values(by=[0], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 1003)\n",
      "(9840,)\n"
     ]
    }
   ],
   "source": [
    "transformed_val = df_val[['edited', 'score', 'num_comments']].to_numpy()\n",
    "labels_val = df_val['verdict']\n",
    "X_val = np.array(np.hstack((transformed_val, vectorizer.transform(df_val['body']).toarray())))\n",
    "y_val = np.array(labels_val)\n",
    "del transformed_val\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2996.29 MiB, increment: -0.23 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process = make_pipeline(PowerTransformer(method='yeo-johnson'))\n",
    "# ct = ColumnTransformer([(\"power\", process, [x for x in range(0, 6)])], remainder='passthrough')\n",
    "# X_train = ct.fit_transform(X_train)\n",
    "# X_test = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2996.29 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(Variable(torch.from_numpy(X_over.astype(np.float32))), \n",
    "                                   Variable(torch.from_numpy(y_over.astype(np.long))))\n",
    "test_dataset = Data.TensorDataset(Variable(torch.from_numpy(X_val.astype(np.float32))), \n",
    "                                  Variable(torch.from_numpy(y_val.astype(np.long))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainHelper():\n",
    "    '''\n",
    "    Helper class that makes it a bit easier and cleaner to define the training routine\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,model,train_set,test_set,opts):\n",
    "        self.model = model \n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.epochs = opts['epochs']\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=opts['lr'], weight_decay=opts['weight_decay']) # optimizer method for gradient descent\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()                      # loss function\n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                                        batch_size=opts['batch_size'],\n",
    "                                                        shuffle=True)\n",
    "        self.test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                                       batch_size=opts['batch_size'],\n",
    "                                                       shuffle=True)\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.train() #put model in training mode\n",
    "        self.train_accuracy = []\n",
    "        self.train_bacc = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.tr_loss = []\n",
    "            for i, (data,labels) in notebook.tqdm(enumerate(self.train_loader),\n",
    "                                                   total = len(self.train_loader)):\n",
    "                self.model.train()\n",
    "                data, labels = data.to(self.device),labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(data)  \n",
    "                loss = self.criterion(outputs, labels) \n",
    "                loss.backward()                        \n",
    "                self.optimizer.step()                  \n",
    "                self.tr_loss.append(loss.item())\n",
    "                y_pred_softmax = torch.log_softmax(outputs.data, dim = 1)\n",
    "                _, predicted = torch.max(y_pred_softmax, dim = 1)\n",
    "#                 self.train_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
    "                self.train_accuracy.append(accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "                self.train_bacc.append(balanced_accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "\n",
    "            \n",
    "            self.test(epoch) # run through the validation set\n",
    "        \n",
    "    def test(self,epoch):\n",
    "            \n",
    "            self.model.eval()    # puts model in eval mode - not necessary for this demo but good to know\n",
    "            self.test_loss = []\n",
    "            self.test_accuracy = []\n",
    "            self.test_bacc = []\n",
    "\n",
    "            \n",
    "            for i, (data, labels) in enumerate(self.test_loader):\n",
    "                \n",
    "                data, labels = data.to(self.device),labels.to(self.device)\n",
    "                \n",
    "                # pass data through network\n",
    "                # turn off gradient calculation to speed up calcs and reduce memory\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(data)\n",
    "                \n",
    "                # make our predictions and update our loss info\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                self.test_loss.append(loss.item())\n",
    "                y_pred_softmax = torch.log_softmax(outputs.data, dim = 1)\n",
    "                _, predicted = torch.max(y_pred_softmax, dim = 1)\n",
    "#                 self.test_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
    "                self.test_accuracy.append(accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "                self.test_bacc.append(balanced_accuracy_score(labels.cpu(), predicted.cpu()))\n",
    "\n",
    "            \n",
    "            print('epoch: {}, train loss: {}, test loss: {}, train acc: {}, train balacc: {}, test acc: {}, test balacc: {}'.format( \n",
    "                  epoch+1, np.mean(self.tr_loss), np.mean(self.test_loss), \n",
    "                  np.mean(self.train_accuracy), np.mean(self.train_bacc), np.mean(self.test_accuracy), np.mean(self.test_bacc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, classes):\n",
    "        super(FFNet, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(input_size, 2000)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.drop1 = torch.nn.Dropout(0.8)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(2000)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(2000, 1000)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.drop2 = torch.nn.Dropout(0.5)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(1000)\n",
    "\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(1000, 500)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.drop3 = torch.nn.Dropout(0.2)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(500)\n",
    "\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(500, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, classes):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden = 1024\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=self.hidden,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=0.8)\n",
    "\n",
    "        self.fc = nn.Linear(2*self.hidden, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFNet(input_size=input_size, classes=num_classes)\n",
    "opts = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 4e-3,\n",
    "    'epochs': 5,\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "NetTrainer = TrainHelper(model = model,\n",
    "                      train_set = train_dataset,\n",
    "                      test_set = test_dataset,opts = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959d621420dc4759812639c1d713e8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1, train loss: 0.655889986646182, test loss: 0.6291873636957886, train acc: 0.6237893429935074, train balacc: 0.6257836019324952, test acc: 0.7259875541125542, test balacc: 0.6289445668737896\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02e2c35748b4d60a2fa071a2e41c306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2, train loss: 0.632965792867976, test loss: 0.6132724323830048, train acc: 0.633426898353184, train balacc: 0.6356012965655697, test acc: 0.7195616883116883, test balacc: 0.6403187992098592\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685ccd2278884f8491d04977500300de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3, train loss: 0.6235480839610433, test loss: 0.6191815002398058, train acc: 0.6396091768069829, train balacc: 0.6418738722934059, test acc: 0.7011634199134199, test balacc: 0.6543372211459197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecc3ed629a048e8a3d787ce4e9b189f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4, train loss: 0.619640353656868, test loss: 0.6263810138810765, train acc: 0.6441204193898611, train balacc: 0.646349147122942, test acc: 0.702922077922078, test balacc: 0.6568338283729472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19e23bf4762493b8db349f0ac76992d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1789.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5, train loss: 0.6167100477211964, test loss: 0.7020087137624815, train acc: 0.6476806714107581, train balacc: 0.6499614218265084, test acc: 0.6766098484848484, test balacc: 0.6588623976314104\n"
     ]
    }
   ],
   "source": [
    "NetTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, verbose=2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000, verbose=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 4451\n",
      "FP: 1071\n",
      "TN: 1616\n",
      "FN: 2702\n",
      "Accuracy: 0.6165650406504065\n",
      "BER: 0.3881646937418832\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "TP_ = np.logical_and(y_pred, y_val)\n",
    "FP_ = np.logical_and(y_pred, np.logical_not(y_val))\n",
    "TN_ = np.logical_and(np.logical_not(y_pred), np.logical_not(y_val))\n",
    "FN_ = np.logical_and(np.logical_not(y_pred), y_val)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'BER: {BER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(verbose=2)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "TP_ = np.logical_and(y_pred, y_val)\n",
    "FP_ = np.logical_and(y_pred, np.logical_not(y_val))\n",
    "TN_ = np.logical_and(np.logical_not(y_pred), np.logical_not(y_val))\n",
    "FN_ = np.logical_and(np.logical_not(y_pred), y_val)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'BER: {BER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'predict_aita_nn.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net(input_size=input_size, classes=num_classes)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
